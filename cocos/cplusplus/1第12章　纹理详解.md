# 第12章　纹理详解

纹理是游戏开发中一个非常重要的话题，特别是对于大型游戏的开发，控制好纹理至关重要。图片往往占据了一个游戏中的大部分内存和游戏安装包的体积，纹理的加载也经常是游戏卡住的原因，纹理的渲染也是影响游戏运行效率的因素，如何使用纹理来实现各种各样的效果，如何管理纹理，更高效地加载、渲染纹理，在不同的平台上如何根据平台的特性更好地使用纹理，这些都是本章要讨论的内容。

纹理是加载到内存中，用于渲染的一组图像数据。将一个纹理应用到一个图元表面的操作，称之为纹理贴图。纹理有1D、2D、3D纹理，1D纹理是一条线，2D纹理是N条线组成的平面，3D纹理则是由N个平面一层一层叠起来的立体空间。

纹理和图像是两个很相近的概念，但图像的概念更广泛。纹素是纹理元素的简称，是纹理空间中的基本单元，图像由像素排列而成，纹理则是由纹素排列而成。使用图片生成纹理之后，像素转换成了纹素，同样保存着颜色数据，但像素作为一个测量单位，而纹素存在于一个虚拟无尺寸的数学坐标系中，无论纹理对应图像的尺寸大小是多少，纹理尺寸永远是从0～1，纹理坐标系中，S、T、R这3个轴分别对应三维坐标系的X、Y、Z这3个轴。

本章会涉及OpenGL中纹理相关的知识，以及在Cocos2d-x中的使用与管理，将详细介绍常用的纹理格式、纹理压缩，以及一些纹理相关的优化方法。本章主要介绍以下内容：

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　在Cocos2d-x中使用纹理。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　管理纹理。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　纹理格式。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　纹理压缩。

## 12.1　在Cocos2d-x中使用纹理

在Cocos2d-x中，纹理被封装到了Texture2D中，Texture2D是Sprite以及一切可显示对象的基础，除了基础图元，其他一切可显示对象最底层都是基于Texture2D，它主要提供图片解析、纹理生成以及纹理渲染等基础功能。虽然在多数情况下不需要直接操作到Texture2D对象，但还是有必要了解Texture2D可以做什么，以及如何使用Texture2D，因为我们需要做得更好（对初学者而言，本节可以跳过的）。

### 12.1.1　Texture的初始化

使用new来手动创建一个Texture2D对象之后，可以通过initWithData（传入加载到内存中的二进制数据）、initWithImage（传入一个加载了内存的Image对象）和initWithString（传入一个字符串，使用平台相关的方法来创建该字符串的纹理）初始化Texture2D。但一般情况下是直接创建Sprite，通过Sprite间接地创建纹理，或者使用TextureCache的addImage函数来返回一个纹理对象。

```
//从TextureCache中加载纹理
Texture2D *tex1 = TextureCache::getInstance()->addImage("test.png");
//手动创建纹理，一般不建议这么做
Texture2D *tex2 = new Texture2D();
tex2->initWithString("String Texture", "Arial", 24);
//在创建精灵时自动会创建纹理
Sprite *sp = Sprite::create("test.png");
```

Texture2D会根据外部传入的纹理数据初始化纹理，也就是说，其不负责纹理文件的读取，只负责纹理文件的解析，Texture2D实现了initWithData、initWithMipMaps、initWithImage和initWithString几种初始化接口。不论是哪个接口，最终都会调用到initWithMipMaps。下面来看一下Texture2D内部的初始化流程。

Texture2D的初始化主要考虑3个问题：MipMap（稍后介绍）、纹理压缩和纹理格式转换。在初始化的过程中，会调用OpenGL函数将整个纹理的内存复制一遍，OpenGL是基于CS模式的，解析好的内存位于Client空间中，通过调用glTexImage2D或glCompressedTexImage2D接口来将纹理数据传输到Server空间中，也就是OpenGL的内部。

MipMap意味着这个纹理有多张图片，而且是多张内容一样但尺寸不一样的图片，这是为了**提高渲染的质量和效率**，但显然会**增加额外的内存**，这种技术也被称为LOD（Level of Details）。如果纹理使用了MipMap，Texture2D将不支持转换该纹理格式。

对于压缩的纹理，Texture2D会调用不同的OpenGL接口来处理，压缩的纹理和MipMap并不冲突，是非常不错的选择。

纹理格式转换会发生在普通的纹理上，从格式A转到格式B的时候，Texture2D会分配额外的大块内存来存储转换后的纹理，在此次加载完成之后释放。

### 12.1.2　纹理和Sprite的关系

Sprite是依赖纹理来进行渲染的，纹理描述了要渲染的数据是怎样的，即要渲染的东西。而Sprite描述了要渲染的方法是怎样的，即如何渲染。

一个Sprite只可以对应一张纹理，或者一张纹理中的一部分，对应多张的情况，可以使用子节点来进行组合，而一张纹理可以对应多个Sprite，这实现了数据的复用。

### 12.1.3　POT和NPOT

POT和NPOT在这里指的是图片的宽和高，POT是Power Of Two的缩写，表示图片的宽和高都是2的幂（乘方的结果），NOPT是Non Power Of Two的缩写，表示图片的宽和高不需要是2的幂。

为了方便对齐处理，早期的设备要求要渲染的图片的宽高为POT，如果使用了NPOT的图片，渲染会出现异常（如显示不出来或者图片被严重拉伸），所以使用POT纹理的主要目的是兼容旧的设备。另外，由于字节对齐，可能也会给纹理的渲染带来一点效率提升。

那么，多旧的设备才需要使用POT纹理来进行兼容呢？iPhone 3GS（2009年发布）之前的iOS设备是不支持NPOT的，Android设备目前还没有发现不支持NPOT的。

使用NPOT有什么好处呢？其最大的好处就是节省内存空间。将一张POT图片调整为NPOT图片，图片本身占用的磁盘空间没什么变化，但加载该图片所需的内存会少很多。

POT和NPOT最大的区别就是，由于POT需要按照2的幂来对齐，所以需要占用额外的白边，也就是透明部分，这部分不会占用多少磁盘空间，但在加载到内存中时，会占用大量的内存。

NPOT允许Texture Packer等工具更好地压缩纹理，**将图片的空白处尽量塞满，来达到优化内存的作用**。另外，在Apple的iOS 4.x之前存在一个关于MipMap的BUG，会导致使用POT纹理会占用额外的内存。

如果需要使用NPOT纹理，对于1.x的Cocos2d-x版本，需要在ccConfig.h文件中开启对NPOT的支持 —— #define CC_TEXTURE_NPOT_SUPPORT 1。

### 12.1.4　纹理混合Blend

纹理混合决定了在同一个位置，叠加渲染多种颜色时的最终颜色。正常情况下，**任何绘制操作只会是被丢弃或者完全覆盖**，如果希望纹理叠加在一起时能够看到颜色混合的效果，那么就需要使用OpenGL的混合功能。

OpenGL在渲染时，会将颜色值放到OpenGL的颜色缓冲区，并将**每个片段**的深度值放到OpenGL的深度缓冲区中。当关闭深度测试时，颜色会直接被替换，而开启深度测试时，离摄像机更近的片段的颜色会覆盖原先的颜色。而开启了OpenGL的混合功能，这些颜色的组合方式不同可以产生各种各样的混合效果。

颜色混合通过glEnable(GL_BLEND)开启，使用glDisable(GL_BLEND)关闭。在开启时，将要渲染的颜色（源颜色）会和颜色缓冲区中当前的颜色（目标颜色）进行一次混合运算，并将运算后的最终值存入颜色缓冲区中。颜色计算指对颜色的RGBA值进行计算（浮点数，范围为0～1），运算默认遵循以下公式：

最终颜色Cf =(源颜色Cs×源颜色的混色参数S) + (目标颜色Cd×目标颜色的混色参数D)

混色参数使用glBlendFunc(GLenum S, GLenum D)进行设置，S和D表示源颜色和目标颜色的混色参数**枚举**。常用的枚举值如图12-1所示。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155402.jpeg)

图12-1　混色参数含义

通过设置源颜色和目标颜色的混色参数枚举，可以调整颜色混合的效果，另外，还可以调整颜色计算的公式，默认的操作是对（源颜色×源颜色的混色参数）和（目标颜色×目标颜色的混色参数）进行相加，在公式中的参数Cf为Color Final，Cs为Color src，Cd为Color dst，通过调用glBlendEquation(GLenum mode) 函数可以改变公式的操作，mode作为枚举值有的意义，如图12-2所示。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155403.jpeg)

图12-2　混合操作枚举

在Cocos2d-x中所有继承于BlendProtocol的显示对象，如Sprite、Layer、Armature、ParticleSystem等，都可以通过下面两个接口来设置和查询纹理混合。

```
//设置BlendFunc
void setBlendFunc(const BlendFunc &blendFunc)
//获取BlendFunc
const BlendFunc &getBlendFunc()
```

BlendFunc是Cocos2d-x对OpenGL混合参数的一个封装，可以通过操作其src和dst成员变量来设置混色参数，并定义了以下4个静态常量来表示4种常用的混色参数组合。

```
//禁用混合 {GL_ONE, GL_ZERO}
static const BlendFunc DISABLE;
//Alpha预乘的混合 {GL_ONE, GL_ONE_MINUS_SRC_ALPHA}
static const BlendFunc ALPHA_PREMULTIPLIED;
//没有使用Alpha预乘的混合 {GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA}
static const BlendFunc ALPHA_NON_PREMULTIPLIED;
//叠加混合 {GL_SRC_ALPHA, GL_ONE}
static const BlendFunc ADDITIVE;
```

### 12.1.5　Alpha预乘

当使用颜色混合的时候，多数情况下都会执行源颜色乘以混色参数的操作，对常用的Alpha混合，需要先将RGB的值乘以自己的Alpha。Alpha预乘的意思是在导出图片资源的时候，RGB的值就已经算好了。这样在进行Alpha混合的时候就可以减少计算量，从而提高效率。

纹理的Alpha预乘，可以在Texture Packer导出图片时，选中Premultiply alpha复选框，这样可以导出预乘了Alpha的图片，如图12-3所示。在Texture2D解析图片时，会根据图片信息来确定该纹理是否进行了预乘，并设置自身的_hasPremultipliedAlpha属性，当使用Texture2D进行混色渲染时，会根据Texture2D是否进行了预乘来决定要使用的BlendFunc。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155404.jpeg)

图12-3　Alpha预乘

### 12.1.6　纹理参数

使用glTexParameter函数来设置纹理参数，可以影响纹理的渲染规则和纹理贴图的行为。glTexParameter函数一共有4个，分别表示4种不同的参数数据类型：

```
//设置GLfloat 类型的纹理参数
void glTexParameterf(GLenum target, GLenum pname, GLfloat param);
//设置GLint 类型的纹理参数
void glTexParameteri(GLenum target, GLenum pname, GLint param);
//设置GLfloat *类型的纹理参数
void glTexParameterfv(GLenum target, GLenum pname, GLfloat *param);
//设置GLint *类型的纹理参数
void glTexParameteriv(GLenum target, GLenum pname, GLint *param);
```

其中，target表示参数要应用在哪个纹理模式上，值可以为GL_TEXTURE_1D、GL_TEXTURE_2D和GL_TEXTURE_3D，pname指定了要设置的纹理参数名称，param指定了纹理参数的值。

在Cocos2d-x中将纹理参数封装到了Texture2D中，使用Texture2D的void setTexParameters(const TexParams& texParams) 方法传入一个TexParams对象可以设置纹理过滤和环绕的参数。

```
typedef struct _TexParams
{
    GLuint    minFilter;
    GLuint    magFilter;
    GLuint    wrapS;
    GLuint    wrapT;
}TexParams;
```

### 12.1.7　纹理过滤Texture Filter

在使用纹理时，纹理经常会被拉伸或收缩（如将纹理贴到一个多边形上，或进行缩放），**根据一个拉伸或收缩的纹理贴图计算颜色片段的过程称为纹理过滤**。OpenGL使用放大过滤器来处理纹理拉伸的情况，使用缩小过滤器来处理纹理收缩的情况。可以使用glTexParameter来设置放大过滤器和缩小过滤器的过滤方法。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　纹理参数GL_TEXTURE_MAG_FILTER为放大过滤器。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　纹理参数 GL_TEXTURE_MIN_FILTER为缩小过滤器。

可以为这两个基本过滤器指定线性过滤和最邻近过滤方法，只需要为glTexParameteri的param赋值即可。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_NEAREST为最邻近过滤，**最快速但过滤效果较差**，会失真。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_LINEAR为线性过滤，**少许额外的开销，但效果会好很多**。

下面是某本书中的Demo，图12-4使用了GL_NEAREST过滤，图12-5使用了GL_LINEAR过滤。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155405.jpeg)

图12-4　Nearest过滤

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155406.jpeg)

图12-5　Linear过滤

通过对比可以发现，使用了GL_NEAREST过滤的图片像素颗粒明显，而使用了GL_LINEAR过滤的图片则好很多。

在Cocos2d-x的TestCpp中，Texture2DTest的"AntiAlias / Alias textures"也是使用了线性过滤来优化渲染效果，在Demo中通过放大两个纹理，效果如图12-6所示。可以明显地看到，右边的人物比左边的人物锯齿要严重很多，因为左边使用了线性过滤，而右边使用了最邻近过滤（这是默认设置）。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155407.jpeg)

图12-6　抗锯齿

通过调用Texture2D的setAntiAliasTexParameters，可以让纹理拥有抗锯齿的能力，setAntiAliasTexParameters内部设置了纹理的过滤器为线性过滤。而Texture2D的setAliasTexParameters将纹理的过滤器设置为最邻近过滤。

除了前面两种基本纹理过滤之外，还有一种被广泛支持的OpenGL扩展——各向异性过滤，可以极大地提高纹理过滤的质量（虽然在Cocos2d-x中一般用不到）。3D物体表面与摄像机的夹角造成的纹理扭曲被称为各向异性，而各向异性过滤是考虑了观察角度的纹理过滤。

下面是使用了各向异性过滤和普通过滤的对比图。图12-7使用了各向异性过滤，而图12-8没有，可以看到图12-8隧道的远处是模糊的。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155408.jpeg)

图12-7　各向异性过滤

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155409.jpeg)

图12-8　线性过滤

使用各向异性过滤的3个步骤如下。

（1）查询是否支持各向异性过滤扩展：

```
gltIsExtSupported("GL_EXT_texture_filter_anisotropic");
```

（2）获取各向异性过滤所支持的最大常量：

```
GLfloat fLargest; glGetFloatv(GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT, &fLargest);
```

（3）设置纹理参数：

```
glTexParameterf(GL_TEXTURE_2D, GL_MAX_TEXTURE_MAX_ANISOTROPY_EXT, fLargest);
```

### 12.1.8　纹理环绕

正常情况下，纹理坐标的范围是0～1，当指定的纹理坐标在范围之外时，OpenGL会根据当前的纹理环绕模式来处理，环绕模式有以下几种。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_REPEAT：重复环绕。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_CLAMP：截取环绕。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_CLAMP_TO_EDGE：截取到边缘环绕。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_CLAMP_TO_BORDER：截取到边框环绕。

GL_REPEAT可以使用一小块纹理来重复地绘制一大片内容，再平铺到一个大的几何平面上。如果没有重复环绕功能，要实现这样的效果就只能创建非常多的Sprite来进行拼接，或者直接使用一张巨大的图片，不管哪种做法，都没有重复环绕简洁、高效。

Cocos2d-x的TestCpp中，Texture2DTest的“Texture GL_REPEAT”例子演示了在Cocos2d-x中如何使用纹理重复环绕。

为纹理设置如下的纹理参数，然后设定纹理的显示区域（这个矩形远远大于这个图片的大小，表示整个贴图背景的大小），效果如图12-9所示，纹理必须是POT图片，即宽和高都是2的幂，否则程序会崩溃。代码如下：

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155410.jpeg)

图12-9　GL_REPEAT环绕

```
auto sprite = Sprite::create("Images/pattern1.png", Rect(0, 0, 4096, 4096));
Texture2D::TexParams params = {GL_LINEAR, GL_LINEAR, GL_REPEAT, GL_REPEAT};
sprite->getTexture()->setTexParameters(params);
```

为什么会有3种截取环绕模式呢？纹理环绕对于纹理贴图的边缘如何进行纹理过滤有着非常大的影响！当使用线性过滤时，需要计算纹理坐标周围像素的平均值，重复环绕可以非常简单地得到处理，而截取环绕则会有多种情况。那么这3种截取环绕模式又有什么区别呢？下面可以看一下不同的截取环绕模式的效果。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_CLAMP对范围外的纹理坐标使用边界纹理单元和边界像素融合后的值，效果如图12-10所示。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155411.jpeg)

图12-10　GL_CLAMP效果

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_CLAMP_TO_EDGE 强制对范围外的纹理坐标使用边界像素，即沿着合法的纹理单元的最后一行或者最后一列进行采样，效果如图12-11所示。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155412.jpeg)

图12-11　GL_CLAMP_TO_EDGE效果

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_CLAMP_TO_BORDER对范围外的纹理只使用边界纹理单元，效果如图12-12所示。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155413.jpeg)

图12-12　GL_CLAMP_TO_BORDER效果

边界纹理单元是围绕在纹理边缘的额外的行和列，与纹理图形一起被加载，默认是透明颜色，可以看到GL_CLAMP的纹理边缘是半透明的颜色，因为边界纹理单元和最边缘的纹理像素进行了融合。当在拼接一些纹理时，如果纹理交接的边缘处出现了缝隙痕迹，可以设置GL_CLAMP_TO_EDGE模式来解决。前面说过，在纹理的坐标系中，S、T、R这3个轴分别对应三维坐标系的X、Y、Z3个轴。而使用纹理环绕时，需要指定是哪个方向的纹理环绕。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_TEXTURE_WRAP_S纹理环绕方向S。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_TEXTURE_WRAP_T 纹理环绕方向T。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_TEXTURE_WRAP_R 纹理环绕方向R。

### 12.1.9　Mip贴图

使用Mip贴图可以提高渲染性能以及渲染的效果，主要是为了解决纹理进行缩放时的闪烁效果（如锯齿假影效果），**以及提高纹理缩放时的纹理过滤效率**。

当对一张巨大的纹理进行缩小时，纹理过滤会对整张纹理进行计算，但屏幕显示的只是很小的一部分，这将造成性能的浪费。

Mip贴图使用多张不同分辨率的纹理（分为多个层），根据当前纹理在屏幕上的实际尺寸来决定使用高清版还是低清版的纹理进行渲染。但因为使用了多张不同分辨率的纹理，所以Mip贴图会导致额外的内存占用。

那么，应该如何使用Mip贴图呢？第一种方法是通过多次调用glTexImage函数来加载，通过指定level参数来决定当前加载的图像处于Mip的哪一层。层数从0开始，在没有使用Mip贴图的情况下，只有第0层的纹理会被加载。为了使用Mip贴图，所有的Mip层都必须加载，可以设置GL_TEXTURE_BASE_LEVEL和GL_TEXTURE_MAX_LEVEL纹理参数来指定只加载需要的Mip层。

```
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_BASE_LEVEL, 0);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAX_LEVEL, 4);
```

手动加载Mip贴图需要准备多张从大到小的图片，非常麻烦，并且还需要额外的图片资源，OpenGL另外提供了一种简单的方法，使用void glGenerateMipmap(GLenum target)根据基础纹理**自动生成其他的Mip层**，非常方便。一般，传入GL_TEXTURE_2D作为target参数。

在Mip贴图中的纹理过滤中，可以使用以下过滤模式，只有使用了Mip贴图的过滤模式，Mip贴图才会真正生效。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_NEAREST：在Mip基层执行最邻近过滤。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_LINEAR：在Mip基层执行线性过滤。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_NEAREST_MIPMAP_NEAREST：选择最邻近的Mip层，执行最邻近过滤。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_NEAREST_MIPMAP_LINEAR：在Mip层之间执行线性插补，并执行最邻近过滤。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_LINEAR_MIPMAP_NEAREST：选择最邻近的Mip层，执行线性过滤。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_LINEAR_MIPMAP_LINEAR：在Mip层之间执行线性插补，并执行线性过滤。

在Cocos2d-x中使用Mip贴图时，需要调用Texture2D的generateMipmap函数，以及置纹理过滤的参数为Mip过滤。Cocos2d-x的TestCpp中，Texture2DTest的“Texture Mipmap”例子演示了Mip贴图的使用效果，如图12-13所示。仔细观察可以发现左边使用了Mip贴图的精灵显示更加平滑了，而右边没有使用Mip贴图的精灵在缩放的过程中存在较强烈的锯齿感。使用Mip贴图的代码如下：

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155414.jpeg)

图12-13　Texture Mipmap效果

```
texture0->generateMipmap();
Texture2D::TexParams texParams =
{
   GL_LINEAR_MIPMAP_LINEAR,
   GL_LINEAR,
   GL_CLAMP_TO_EDGE,
   GL_CLAMP_TO_EDGE
};
texture0->setTexParameters(texParams);
```

### 12.1.10　渲染纹理

Texture2D提供了在指定坐标处渲染纹理，以及在矩形范围内渲染纹理的功能，想要手动渲染Texture2D纹理，首先需要创建纹理，然后在节点的draw函数中，调用纹理对象的drawAtPoint或drawInRect方法执行渲染。

如果是Cocos2d-x 3.0之后的版本，需要创建一个CustomCommand渲染命令，添加到renderer中，在渲染命令的回调中执行纹理的drawAtPoint或drawInRect（在第15章中将详细介绍）。渲染的位置会根据当前的变换矩阵进行计算，也就是说位置坐标是基于当前节点坐标系的。

drawAtPoint将在传入的点上，按照纹理本身的大小进行绘制，渲染的点的位置是经过矩阵变换后的位置，该点对应纹理的左下角。该函数相当于宽和高都等于纹理尺寸的drawInRect。

drawInRect将根据当前的纹理参数，在一个矩形范围内绘制整张纹理，可以传入任意大小的一个矩形，纹理会根据矩形进行缩放，渲染的效果如图12-14所示。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155415.jpeg)

图12-14　drawInRect效果

```
void TextureDrawInRect::draw(Renderer *renderer, const Mat4 &transform, 
uint32_t flags)
{
    TextureDemo::draw(renderer, transform, flags);
    //初始化CustomCommand并添加到renderer中
    _renderCmd.init(_globalZOrder);
    _renderCmd.func = CC_CALLBACK_0(TextureDrawInRect::onDraw, this,
    transform, flags);
    renderer->addCommand(&_renderCmd);
}
void TextureDrawInRect::onDraw(const Mat4 &transform, uint32_t flags)
{
    Director* director = Director::getInstance();
    CCASSERT(nullptr != director, "Director is null when seting matrix
    stack");
    director->pushMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_MODELVIEW);
    director->loadMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_MODELVIEW,
    transform);
    auto s = Director::getInstance()->getWinSize();
    //在指定的矩形中渲染整张图片
    auto rect1 = Rect( s.width/2 - 80, 20, _tex1->getContentSize().width *
    0.5f, _tex1->getContentSize().height *2 );
   auto rect2 = Rect( s.width/2 + 80, s.height/2, _tex1->getContentSize().
   width * 2, _tex1->getContentSize().height * 0.5f );
    _tex1->drawInRect(rect1);
    _Tex2F->drawInRect(rect2);
    director->popMatrix(MATRIX_STACK_TYPE::MATRIX_STACK_MODELVIEW);
}
```

## 12.2　管理纹理

本节来学习纹理的管理，本节的内容比在Cocos2d-x中使用纹理更加实用一些，因为多数情况下是在不知不觉间使用的纹理，并没有直接对纹理进行操作。

Cocos2d-x中对纹理的管理，很大程度上就是对内存的管理，因为一般纹理占用的内存是最多的。Cocos2d-x提供了TextureCache来管理纹理，本节会介绍TextureCache的使用，纹理的生命周期，如何管理纹理以及加载纹理的技巧和异步加载。只有了解了函数背后的细节，才能知道应该注意的问题。

### 12.2.1　使用TextureCache管理纹理

TextureCache作为一个管理纹理的单例，在3.x之后，需要从Director中获取它，而不是直接调用TextureCache的getInstance方法（该方法将会被废弃），TextureCache内部会以纹理的名字作为key，这里的名字指的是通过fullPathForFilename转换后的图片文件的完整路径。

从文件名到key的转换由TextureCache自动完成，不需要关心，所有的Sprite对应的纹理默认都在TextureCache中，当使用一张图片创建了很多个同样的Sprite对象时，Texture2D对象只会有一个，所有Sprite都是共用这个Texture2D对象。下面先介绍TextureCache的接口：

```
//根据传入的filepath，加载并返回Texture2D
//当纹理已被加载时直接返回
Texture2D* addImage(const std::string &filepath);
//根据传入的filepath，异步加载Texture2D，加载完成后回调callback
//当纹理已经被加载时直接回调callback
virtual void addImageAsync(const std::string &filepath, const std::
function<void(Texture2D*)>& callback);
//解绑正在异步加载的filename文件的回调，该文件加载完成之后回调不会被调用
virtual void unbindImageAsync(const std::string &filename);
//解绑所有正在异步加载的图片的回调
virtual void unbindAllImageAsync();
//根据Image对象和key来创建一个Texture2D对象并返回
//当指定的key没有对应Texture2D对象才会创建新的Texture2D，如果有则直接返回
//这个key不会被转换为完整路径，只是一个单纯的key
Texture2D* addImage(Image *image, const std::string &key);
//根据key来获取Texture2D，如果找不到，则会将其转换为完整路径然后再次查找
Texture2D* getTextureForKey(const std::string& key) const;
//重新加载对应纹理的图片，如果没有加载该纹理，则直接加载
//如果存在该Texture2D对象，则对该纹理调用initWithImage重新初始化该纹理
//该方法可用于更新资源后重新刷新纹理，但在3.3版本的代码中发现内存泄漏BUG，使用new
操作符创建了Image对象之后并没有被释放
bool reloadTexture(const std::string& fileName);
//清除所有的纹理，对所有的纹理调用release
//并从cache中清除
void removeAllTextures();
//清除所有当前没有被外部引用到的纹理，该操作会使用纹理
//当进入了一个新的场景时可以调用该方法来清理
void removeUnusedTextures();
//遍历所有被cache的纹理，如果找到与texture匹配的纹理，则删除
void removeTexture(Texture2D* texture);
//根据纹理的名字来删除纹理
void removeTextureForKey(const std::string &key);
//输出当前cache中所有纹理的详细信息以及占用的内存总量
std::string getCachedTextureInfo() const;
```

在管理纹理之前，需要先了解一下纹理资源的生命周期。纹理的加载接下来会详细介绍，这里要了解的是加载之后的事情。加载完之后就会使用它，用完之后应该删除。

当将纹理加载到TextureCache中时，除非明确地调用删除纹理的方法，否则，纹理会在程序结束的时候，才由Cocos2d-x来进行释放。当游戏从场景A切换到场景B，这时候场景A中的所有纹理仍然在内存中，如果没有管理好它们，那么程序的内存很快就会用完。

清理纹理的一个简单的原则是，**这个纹理在接下来的短时间内不会再用到**。

因此切换场景时显然是一个清理纹理的好时机，应该在新场景的onEnter中调用TextureCache的removeUnusedTextures，如果在旧场景的onExit中调用或者在新场景的init中调用，则会有很多东西清理不干净。场景切换的流程如下：

（1）创建新场景，并调用新场景的init初始化。

（2）调用Director的replaceScene切换场景。

（3）旧场景执行onExit回调。

（4）释放旧场景。

（5）执行新场景的onEnter回调。

而新场景的init和旧场景的onExit都位于释放旧场景之前，这时候场景中的Sprite还引用着texture对象，直到Sprite被析构。调用removeAllTextures可以将所有的纹理都清理干净，但这可能不是我们想要的结果。removeUnusedTextures应该在加载新场景的资源之前调用，以保证内存的峰值不会过高，例如旧场景的纹理占据了100MB的内存，而新场景需要80MB的内存，如果先加载新场景的纹理，再卸载旧场景的纹理，那么峰值就会达到180MB，对于一些内存较小的设备而言，这是致命的。

另外，如果是希望比较干净地清理内存，removeUnusedTextures并不是一个最佳的选择，应该使用Director的**purgeCachedData**方法，将不需要的缓存清理干净。因为当使用Plist图片时，SpriteFrameCache中的SpriteFrame也对Texture2D进行了retain操作，因此所有不需要再使用的图集都不会被释放。另外purgeCachedData中也对Font和FontAtlas进行了清理，而这正是所需要的。

```
Director::getInstance()->purgeCachedData();
```

看到这里，读者是不是迫不及待地想为所有场景的onEnter回调加上前面的这句代码？如果场景之间切换的频率非常高，并且场景中的资源并没有占用过多的内存，那么保留这些缓存反而会更好。写程序应该去解决一些实际问题，而不是解决一些凭空想象的问题。预测问题也应该根据实际情况进行推测。

如果在运行中调用removeUnusedTextures或者removeAllTextures会不会出现这样的问题：屏幕中使用了这个纹理的对象因为纹理被释放了而一下子变黑了？不必担心这个问题，因为Sprite对Texture2D已经进行了retain操作，从Cache中删除的后果就是**再要创建一个这样的Sprite时，会重新创建纹理。**而对使用旧Texture2D的Sprite不会有任何影响。但这种情况下是不应该去清除Cache的，从逻辑上看可能没有问题，但实际上重新加载纹理可能会导致卡顿，而且一个同样的纹理在内存中存在两份是不可原谅的事情。

将Cache中的资源清理掉之后，再次需要使用这个资源时，会从磁盘中重新加载。当使用purgeCachedData或removeUnusedTextures来清理资源时，有可能清理了这些资源，这将导致一些冗余的操作，影响加载的效率，如从Cache中删除一张图片，然后又马上去加载它，这是有可能发生的。

有两种方法可以避免这样的尴尬，第一种是摒弃purgeCachedData或removeUnusedTextures，手动清除Cache中的纹理，另外一种是在清除之前，将接下来还要使用的纹理手动调用它们的retian方法，清理完之后再调用它们的release方法，可以根据实际情况决定使用哪种方法，而简单的封装会使这个操作变得更轻松。

### 12.2.2　使用TextureCache加载纹理

当调用TextureCache的addImage方法时，TextureCache会判断是否已经加载过该纹理，如果没有则进行加载，创建Texture2D，加载的流程如下：

（1）判断要加载的纹理是否已经在缓存中。

（2）如果不是则使用new操作符创建一个Image对象，并调用initWithImageFile进行初始化。

（3）完成Image的初始化之后，new一个Texture2D并调用initWithImage进行初始化。

（4）完成Texture2D的初始化之后将Texture2D插入缓存Map中，并释放Image。

（5）由于没有对Texture2D调用autorelease或release，所以Texture2D的引用计数为1。

接下来看看Image的initWithImageFile做了什么？

```
bool Image::initWithImageFile(const std::string& path)
{
    bool ret = false;
    //转换文件名为完整路径，并从文件中读取数据
    _filePath = FileUtils::getInstance()->fullPathForFilename(path);
    Data data = FileUtils::getInstance()->getDataFromFile(_filePath);
    if (!data.isNull())
    {
        ret = initWithImageData(data.getBytes(), data.getSize());
    }
    return ret;
}
```

Data是一个普通的临时变量，里面保存了从malloc分配的内存指针，从图片文件中读取出来的数据就放在这块内存中，getDataFromFile调用了getData方法，这是一个平台相关的方法，在Windows下会直接读取图片文件，填充到Data中并返回，但在Android和iOS下，会从数据包中将图片解压出来，并填充到Data中。

```
Data FileUtils::getDataFromFile(const std::string& filename)
{
    return getData(filename, false);
}
```

可以看到，这里返回的Data并不是一个指针，getData函数中的Data临时变量会在函数返回之后被释放。看到这里读者可能会疑惑，如果这样的话，Data所包含的内存不就被释放了吗？Data的析构函数中是会释放其所管理的内存的，我们知道在函数返回的时候，会生成一个临时对象，当返回值赋给这个临时对象的时候，应该会调用Data的=操作符或者拷贝构造函数，在这里Data会重新调用malloc申请一块内存，将传入的Data内部的指针复制过来，那这样不就产生了没必要的内存浪费了吗？

实际上并没有，因为在这里Data使用了**右值引用**，在Data的**移动构造函数**中，将原始Data变量的内存指针保存到了外部接收的Data对象中，并且将它的内存指针置为了nullptr，当临时变量的析构函数被调用时，并不会去释放内存，因为指针已经为空。所以在这里getDataFromFile分配了图片文件存储所需的内存。这时候的图片仍然处于压缩状态。

```
//Data的移动构造函数
Data::Data(Data&& other) :
_bytes(nullptr),
_size(0)
{
    CCLOGINFO("In the move constructor of Data.");
    move(other);
}
void Data::move(Data& other)
{
    _bytes = other._bytes;
    _size = other._size;
    other._bytes = nullptr;
    other._size = 0;
}
```

接下来，在initWithImageData中，首先会判断图片是否经过了ccz或gzip压缩，如果是则进行解压，这时**会分配一块更大的内存**，来保存解压后的图片文件，这块内存的大小是图片进行压缩之前的文件大小，并且会**在处理完成之后立即释放**。如果图片没有经过压缩，那么是不会额外分配这块内存的。

在我们拿到最终的图片文件之后，会检测该图片是何种格式，并根据图片文件的格式，进行相应的解压。这次解压会分配一块内存，这块内存是最大的内存，存储了每个点的像素内容。这时候PNG、JPG等普通文件格式会按照自己的压缩算法进行解压，解压到分配的这块内存中，内存会存在Image的成员变量_data中，在完成图片解析之后返回。

而对于ETC、PVR等纹理压缩格式的处理，则要简单很多，如果硬件支持这种纹理压缩格式，那么这里会分配一块与图片文件差不多大小的内存，然后直接复制过来。

实际上这个内存的分配和复制是可以避免的，只要取出Data指针之后将Data内部的指针置为空即可。即使这里分配了内存，但分配的内存要比非压缩纹理格式少得多，并且没有解压的计算。当然，这些的前提是硬件支持这种纹理压缩格式。如果硬件不支持，Cocos2d-x提供了软解压的支持，但这就与普通的非压缩纹理格式差不多了。

Image的初始化到这里算是完成了，它完成了图片格式解析的工作，将图片文件转换成了可以用来渲染的纹理内存。

接下来看Texture2D的initWithImage，其会根据3种情况进行初始化，第一种是Image中存在多张Mip贴图的情况，其会为一个纹理生成多层的贴图。第二种是使用了纹理压缩的，会直接生成纹理。第三种情况是，如果Texture2D的g_defaultAlphaPixelFormat不为NONE或AUTO，并且图片的像素格式为I8、AI88、RGB888、RGBA8888，并且像素格式不为g_defaultAlphaPixelFormat，则会转换成g_defaultAlphaPixelFormat所表示的像素格式。这个转换又会进行一次内存分配，转换所分配的内存会在初始化完成后释放。

接下来最终会调用到Texture2D的initWithMipmaps，在initWithMipmaps中，如果Texture2D已经生成了一张纹理，那么会调用GL::deleteTexture先将这张纹理删除，再调用glGenTextures生成一张纹理，绑定并设置纹理参数。如果是压缩纹理，会调用glCompressedTexImage2D，而普通纹理则会调用glTexImage2D将最终的这块纹理内存传输到OpenGL的空间中。最后将分配的内存依次释放，这时只有OpenGL内部存储的纹理占用内存了。这里简单总结一下纹理加载过程中的内存申请以及释放，整个流程如图12-15所示。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155416.jpeg)

图12-15　加载纹理占用内存分析

有人建议不要连续地在同一帧中加载纹理，应该平摊到多帧中，以避免在加载的时候，内存的峰值过高，严格来说这种做法并不准确，但这个建议是有道理的。首先来看内存问题，在一个纹理加载完成之后，除了存储在OpenGL中的纹理内存，其他的内存都被释放了，也许在早先的版本，这些内存使用了autorelease，这有可能导致一些内存在这一帧结束后才释放，但现在的释放是非常及时的（当然，很多地方还可以做得更好）。所以对一切说法都要有怀疑精神，**比了解细节更重要的是，分析细节的能力**。

既然在同一帧中连续加载纹理不会导致内存的峰值过高，为什么还要平摊到多帧中来加载呢？这主要是为了减少游戏的卡顿，因为每两帧之间会有一点点睡眠时间，利用好睡眠时间，可以让加载稍微好一点，但更好的方法是使用异步加载。另外，一般的做法是在进入场景之前，先将该场景所需的纹理加载好，对于一些Plist文件，也可以先将Plist对应的图片预加载进来，来提高后面加载Plist的效率。但有一些图片如果在场景中用到的概率比较低，那么就要考虑是否将这样的纹理预加载进来了。

纹理的初始化完成后，最终的纹理数据被存储到了OpenGL中，那么具体是被存储到哪一块内存中呢？接下来的内容属于个人的思考推测，因为不知道OpenGL的底层实现，所以只能是推测。

我们知道，大部分的移动设备和PC都存在两块内存区域，就是**内存和显存**。而OpenGL的底层，是一个基于CS模型（Client-Server）的状态机。可以简单地理解为Client占用了内存，Client端主要由CPU负责。而Server占用了显存（实际情况要复杂很多，如有些设备是直接使用内存来作为显存），Server端主要由GPU负责。

当要渲染一个图片时，调用的OpenGL绘制方法会从Client层向Server层发起请求，这时可能导致一张图片从内存被发送到显存。这样的一个事件会存在一定的性能消耗。当然，OpenGL在显存中肯定是会有相应的Cache机制，但显存有限，所以一定会出现显存不足的情况。这时OpenGL就会将显存中无用的纹理清除，然后将即将渲染的纹理传输到显存中。

根据上面的推测，可以得出一些结论，就是显存越大，渲染的效率越高，因为可以缓存更多的纹理。显卡的带宽越高，渲染的效率越高，因为纹理从内存传输到显卡的速度会更快。渲染大的纹理，比渲染小的纹理更慢，因为要传输更多的数据到显卡上。也就是说，DrawCall有大有小，并不只看数量指标。每台设备的渲染效率都与其显卡设备密切相关，且存在较大的差异。就算是同样的设备，同样的DrawCall数量，由于DrawCall渲染内容的顺序，也可能导致较大的差别。

例如，要渲染A、B、C这3张图片各100次，而显存中只能存下一张图片，如果按照A、B、C的顺序渲染100次，中间就会发生300次传输纹理到显存中的事件。如果是A渲染100次，B渲染100次，最后C渲染100次，那么中间就只会发生3次纹理传输的事件。

### 12.2.3　异步加载纹理

在Cocos2d-x中，异步加载的代码非常简单，仅仅需要调用一个函数就可以实现，调用addImageAsync，Cocos2d-x会创建一条线程来执行异步加载，传入想要加载的纹理和加载完成的回调函数，当纹理被加载到内存中的时候，在主线程中等待的回调函数会被触发，在回调函数中可以处理图片加载完成的代码。先来了解一下Cocos2d-x的异步加载做了什么。

（1）首先判断纹理是否已经加载好，如果是则直接调用回调函数并返回。

（2）接下来判断队列是否为空，如果是则创建队列以及线程，并Schedule自己的addImageAsyncCallBack方法。

（3）将要加载的纹理插入队列的尾部，线程会开始加载。

（4）在线程中，依次加载队列中的纹理，如果纹理已经加载好则跳过加载步骤。

（5）所有纹理加载完成之后，清空释放队列，结束线程。

（6）在主线程的addImageAsyncCallBack回调中，根据加载完的Image创建Texture2D并执行回调。

（7）当所有纹理都加载完成之后，addImageAsyncCallBack会注销自己。

首先，连续调用addImageAsync只会创建一条线程，**同一时间内只存在一条线程，**但可以调用addImageAsync添加多个同样的纹理。正常来说不会出现重复加载同一个纹理的情况，但如果连续异步加载一个比较小的纹理，在主线程处理该纹理之前，加载线程就已经开始执行加载第二个纹理了，那么这时候第一个纹理会被替换掉，并且发生内存泄漏（这是当前3.3版本的BUG）。当然，规规矩矩地使用是很难出现这个BUG的。使用方法如下：

```
//传入自己的回调函数即可，当然也可以使用匿名函数
Director::getInstance()->getTextureCache()->addImageAsync(
    "Images/background.png", CC_CALLBACK_1(TextureAsync::imageLoaded,
    this));
```

在哪里调用异步加载是一个关于调用的代码如何写的问题，也是一个如何把资源加载前、加载中、加载完成连成一条线的问题。使用了异步加载，代码肯定不能像原来那样：

```
MyScene::init()
{
    LoadResource();
    ...
    initGame();
}
```

而应该是：

```
MyScene::init()
{
    LoadResourceAsyn();
}
```

在LoadResourceAsyn结束的时候调用initGame，以确保资源加载完毕之后才开始初始化游戏，在资源加载的过程中，可以显示Loading界面，在异步加载的过程中更新Loading。

## 12.3　纹理格式

纹理格式应该一分为二来看，一个是**图片文件的存储格式**（严格来说这并不是纹理格式），也就是我们可以看到的图片文件，对于存储格式，我们最关心两个问题，一个是**图片文件占用的磁盘空间的大小**（文件有多大），一个是**图片品质的高低**（清晰否）。这取决于图片文件的压缩率是否够高，以及压缩算法是否有损。此外，**加载该图片文件的速度**、引擎是否支持，是否能够解析该文件也是关注的指标之一。

另外一个是**纹理在内存中的存储格式，也称为显示格式，**这种格式是类似RGBA8888、RGB565之类的格式，对于显示格式，最关心的问题就是**占用内存的大小，**也就是图片文件加载之后，解压出来放到内存中的图片占用的内存大小、每个像素在内存中的格式，以及这种显示格式下的图片清晰度是否能够接受、平台是否支持。

本节将介绍一些常用的纹理格式，Cocos2d-x支持JPG、PNG、TIFF、TGA、Webp几种图片格式，以及纹理压缩文件格式PVR、ETC、S3TC、ATITC。对于特殊纹理压缩格式，后面的内容中专门介绍。

JPG的压缩率非常高，但JPG是有损压缩，虽然JPG的文件比较小，同时显示效果也比较差，且不支持透明通道。最让人不能接受的是，将一个JPG图片加载到内存中，占用的内存与PNG相同，但画质却相差甚多，并且解压所需的时间比较多，在加载的时候，需要占用大量额外的内存。JPG的主要应用领域是Web方面。

PNG格式的纹理的压缩比例还是不错的，无损压缩，而且支持透明通道，对于质量要求不太高的图片，可以用图片处理工具直接生成16位的PNG纹理。

TIFF格式是比较复杂的格式，最常用于印刷和扫描，提供了自定义颜色控件，可以存储多幅图形，还可以扩展和修改标准定义。

TGA文件也是无损压缩，用于存储高质量的图像，支持透明通道，结构简单，支持各种不规则的图形，在工业、影视领域应用广泛。

Webp是谷歌开发出来用于替代PNG的格式，也是一种有损的压缩格式，并且在相同的质量下体积比JPG小40%。但编码压缩的时间比JPG长8倍。Webp当前在移动设备上的加载效率比较低，需要花费较长时间。

实际上并没有必要对图片文件进行压缩，因为**在压缩IPA或APK包的时候，会自动进行压缩，**因此如果再次进行压缩，不但压缩率不高，达不到期望的压缩效果，而且使用时需要进行多次解压。如果使用普通的图片格式，可以选择以下像素格式，像素格式决定了纹理所占用的内存大小，以及图片显示的质量，下面是Cocos2d-x所支持的主要像素格式。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　BGRA8888 32位纹理，效果非常好，兼容性高。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　RGBA8888 32位纹理，效果非常好，兼容性比较差。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　RGB888 24位纹理，效果非常好，不支持透明通道。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　RGB565 16位纹理，效果较好，不支持透明通道。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　RGBA4444 16位纹理，色彩比RGB5A1略差，但半透明效果良好。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　RGB5A1 16位纹理，色彩较好，但半透明效果差，透明通道仅用于镂空。

很多开发者只关注图片文件的大小，以及图片显示的效果是否符合需求，而忽略了图片所占内存的大小，或者将图片文件的大小以及图片所占内存的大小混为一谈。

我们知道，一个图片文件所存储的空间，以及这张图片加载到内存之后所占用的内存是不一样的，那么这两者之间的差距有多少呢？以一张简单的PNG图片为例，图片的尺寸为512×512，图片的颜色为32位的RGBA8888，那么这样的图片所占的存储空间有多大呢？2.97KB，如图12-16所示。这样的图片放到内存中会占用多大的内存呢？1MB！这中间的差距是否非常大？你是否会将这张图片视为一张微不足道的小图片？

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155417.jpeg)

图12-16　图片文件

我们来先来看看1MB的内存是怎样算出来的。图片是由一个一个的像素组成的，那么512×512尺寸的图片，就有512×512个像素点，每个像素点占32位，也就是4个字节的内存，根据公式 bytes = width×height×bitsPerPixel / 8，代入这张图片的宽高和像素的位数，可以得到512×512×32/8，也就是1048576个字节，除以1024就是1024KB，再除以1024就是1MB。这就是为什么**只有20MB的图片资源，却可能占了近200MB的内存的原因。**

所以，**决定图片占用多少内存的，是图片的尺寸，以及图片的像素格式。那么决定图片所占用的存储空间大小的是什么呢？是图片的文件格式，以及图片的内容丰富程度。**图片的文件格式决定了以何种方式来压缩图片，如JPG比PNG压缩率高，而Webp又比JPG压缩率高。图片内容越简单，压缩率越高，而越复杂的图片，压缩率越低，当然，图片的像素格式和尺寸也参与决定了图片所占用的存储空间大小。

没错，我们很容易根据一张图片在磁盘空间所占的大小来判断这张图片是大还是小，而忽略了这张图片可能占用的内存，这里要告诉你另外一个事实，就是你看到的图片大小并不是打包之后的图片大小。当将游戏打包成APK和IPA包时，图片是经过了zip压缩的，这张图片会增加多少游戏包的体积，不要直接看图片的大小，而要看这个图片打包成zip之后的大小。当然，这个方法也不是非常准确，但比直接看图片大小要准确得多。

这里只是希望读者了解，费尽心思压缩后的图片，最后进行打包的时候，未必比不压缩的情况下体积更小。有的人对图片先进行了一次zip打包，那么在打包游戏安装包的时候，相当于对这个图片进行了两次zip压缩，压缩率可想而知，并且加载的时候也会导致额外的消耗。

在图片质量要求不是特别高的情况下，应该尽量使用16位的纹理，这样可以有效地节省图片占用的内存以及图片的大小，减少一般的开销，但16位图在显示一些比较平滑的渐变颜色时会比较糟糕，如图12-17和图12-18所示。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155418.jpeg)

图12-17　原图

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155419.jpeg)

图12-18　16位RGBA4444

TexturePacker的**抖动**选项可以很好地优化这个问题，在TexturePacker中选择Dithering选项，如图12-19所示。对于带透明通道的图片，可以选择**FloydSteinbergAlpha**选项，而不带透明通道的图片，可以选择**FloydSteinberg。**当然，读者也可以尝试一下其他的选项。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155420.jpeg)

图12-19　Dithering选项

可以发现，图12-20中抖动之后的图片和图12-21中的原图的效果已经很接近了。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155421.jpeg)

图12-20　16位图抖动后的RGBA4444

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155422.jpeg)

图12-21　原图

## 12.4　纹理压缩

纹理压缩是一种专门为在计算机图形渲染系统中存储纹理而使用的图像压缩技术，与普通图形压缩算法的不同之处在于，**纹理压缩算法为纹素的随机存取做了优化。**纹理压缩的特点是解压速度快，在渲染管线的执行过程中可以高效地解压，从而使压缩纹理在内存中保持压缩的状态，允许对某一纹素进行随机访问，访问到时，只有少量纹素被读取和解压，不需要对整个纹理进行解压。

由于人眼的不精确性，图像渲染更适合使用有损的数据压缩。对于压缩的速度要求并不高，一般在游戏外用工具进行压缩，在程序中直接使用。

**纹理压缩的主要目的是为了节省内存**（也可以起到压缩文件大小的作用），纹理压缩可以**让更多的纹理装入图形硬件**中（也就是显卡），这在移动平台上非常重要，移动设备上支持OpenGL ES的显卡，都支持一种或多种纹理压缩格式。

在OpenGL中缓存更多的纹理，在纹理比较多的情况下，能提高整体的渲染效率。在加载时，压缩纹理比正常纹理占用更小的内存，拥有更快的加载速度。在纹理贴图中，已压缩的纹理和未压缩的纹理使用起来基本没有区别。

随机存取指的是下标操作，将整张图片数据视为一个二维数组，通过image[x][y]来确定一个像素的位置，当然，这个操作是OpenGL渲染纹理的时候执行的。为什么压缩纹理比正常纹理加载要快呢？回顾前面纹理加载流程可以知道，正常纹理在加载的时候需要开辟内存进行解析，将文件解压成可渲染的像素格式，解析的目的是为了能够支持下标操作，只有支持下标操作才能用于渲染。而压缩纹理只需要进行非常简单的解析，而不需要解压。少了开辟内存和解压的操作，加载效率自然快了很多。而压缩纹理在磁盘上所占用的存储空间，就是其所需的内存空间，因为压缩纹理可以直接用于渲染。

除了占用内存以及加载速度之外，另一个非常关心的一个问题就是，这个纹理压缩文件有多大呢？这里还是用一张512×512的PNG图片来进行比较，使用ETC格式来进行对比，PNG图片占2.97KB，而ETC图片占了128KB。是否感觉差距挺大的，如果将这个数据等比增长，那么ETC纹理压缩大约会比PNG多占40倍的空间。但前面讲过要看图片的大小，请看**图片进行zip压缩后的大小，**PNG在zip压缩后是1.92KB，而ETC在压缩之后是1.72KB，反而比PNG占用更少的空间。

另外，因为我们对比的图片是比较简单的图片，而越复杂的图片，占用的空间越大，因为压缩率越低。而纹理压缩不一样，**压缩纹理的图片大小只与压缩格式以及尺寸相关，**对ETC而言，512×512的图片，大小恒为128KB。而内容稍微丰富一些的PNG图片，很容易就超过这个大小了。

OpenGL ES 3.0带来了很多新的特性，其中一项是使用统一的纹理压缩格式ETC，而在这之前，纹理压缩格式包含了S3TC、PVPRTC和ETC等格式，没有一个统一的标准，不同的硬件对这些格式的支持也不同。下面整理了各种纹理压缩格式的特性、像素格式、内存占用以及相关平台。但很多旧的设备并不支持OpenGL ES 3.0，所以为了兼容旧的设备，在OpenGL ES 3.0大力推广之前，还需要针对不同平台进行纹理压缩。

### 12.4.1　纹理压缩格式对比

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　PVRTC：PowerVR系列GPU支持，移动平台上主要用于iOS，压缩率最高，图像质量好。但PVRTC限制图片必须是正方形的POT纹理。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　ATITC：高通Adreno系列GPU支持，来自以前的ATI，排他性较强，压缩率和质量也没有特别出色的地方。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　DXTC / S3TC：NVIDIA Tegra系列，VivanteGC系列，DXTC和S3TC是同一种压缩格式，是在DirectX和OpenGL中的两个称呼，具有不错的压缩率，主要用于PC和WinPhone平台。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　ETC1：ARM的Mali系列GPU支持，前面4个也支持，是OpenGL ES图形标准的一部分，安卓平台广泛支持ETC压缩的GPU加速，缺点是不支持Alpha通道。ETC1需要注意的是，部分显卡不支持NPOT的ETC1纹理，所以尽量使用POT的纹理。

另外，ETC2和ASTC是新出的压缩标准，ETC2相比ETC1，弥补了不支持Alpha通道的缺陷，并且各方面都有提升。ASTC则比S3TC具有更高的压缩速度和图片质量，但目前支持它们的设备还不多。

ETC1扩展名为GL_OES_compressed_ETC1_RGB8_texture，加载压缩纹理时，internal format参数支持以下格式：

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_ETC1_RGB8_OES（像素的格式为RGB，每个像素0.5个字节）。

PVRTC 扩展名为GL_IMG_texture_compression_pvrtc，加载压缩纹理时，internal format参数支持以下格式：

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_COMPRESSED_RGB_PVRTC_4BPPV1_IMG（像素的格式为RGB，每个像素0.5个字节）。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_COMPRESSED_RGB_PVRTC_2BPPV1_IMG（像素的格式为RGB，每个像素0.25个字节）。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_COMPRESSED_RGBA_PVRTC_4BPPV1_IMG（像素的格式为RGBA，每个像素0.5个字节）。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_COMPRESSED_RGBA_PVRTC_2BPPV1_IMG（像素的格式为RGBA，每个像素0.25个字节）。

ATITC扩展名为GL_ATI_texture_compression_atitc，加载压缩纹理时，internal format参数支持以下格式：

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_ATC_RGB_AMD（像素的格式为RGB，每个像素0.5个字节）。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_ATC_RGBA_EXPLICIT_ALPHA_AMD（像素的格式为RGBA，每个像素1个字节）。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_ATC_RGBA_INTERPOLATED_ALPHA_AMD（像素的格式为RGBA，每个像素1个字节）。

S3TC扩展名GL_EXT_texture_compression_dxt1和GL_EXT_texture_compression_s3tc， 加载压缩纹理时，internal format参数支持以下格式：

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_COMPRESSED_RGB_S3TC_DXT1（像素的格式为RGB，每个像素0.5个字节）。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_COMPRESSED_RGBA_S3TC_DXT1（像素的格式为RGBA，每个像素0.5个字节）。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_COMPRESSED_RGBA_S3TC_DXT3（像素的格式为RGBA，每个像素1个字节）。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155401.jpeg)　GL_COMPRESSED_RGBA_S3TC_DXT5（像素的格式为RGBA，每个像素1个字节）。

以上压缩纹理格式每个像素大小相对ARGB8888格式的比例，最高压缩比是16:1，最低压缩比是4:1，对于减小纹理的数据容量有明显作用，相应在显存带宽上也有明显优势，从而提高了游戏的运行效率。

普通纹理和压缩纹理所占用的内存，以及渲染效果对比如图12-22所示，图12-22中的PNG是16位的PNG图片。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155423.jpeg)

图12-22　图片质量对比

### 12.4.2　在Cocos2d-x中使用纹理压缩

在Cocos2d-x中，如何使用压缩纹理呢？因为纹理压缩是需要硬件支持的，所以硬件是否支持这种纹理是首要问题，在Configuration中可以判断是否支持这种纹理压缩格式。如果不支持也没关系，Cocos2d-x为开发者做了软解压的处理，也就是转化成普通的纹理格式，所以即使不支持，也可以进行正常的渲染（这在早期的Cocos2d-x版本中是不支持的）。

如果硬件不支持纹理压缩，而开发者又使用了这种纹理压缩，Cocos2d-x会有日志警告输出。下面这些方法可以帮助判断是否能够支持指定的纹理压缩格式。当然，也可以手动查询OpenGL是否支持该扩展，扩展名在前面已经给出。

```
Configuration::getInstance()->supportsPVRTC();
Configuration::getInstance()->supportsETC() ;
Configuration::getInstance()->supportsS3TC();
Configuration::getInstance()->supportsATITC();
```

不论是否支持纹理压缩，在使用的时候都非常简单，与使用普通的PNG图片一样，在加载纹理或者创建Sprite的时候，只需要将图片名字传进去即可。开发者可以使用TexturePacker将纹理进行压缩，得到想要的纹理格式。

在使用纹理压缩时，最好将资源用配表之类的工具管理起来，在不同平台的游戏打包时，使用不同的纹理压缩格式。一般可以根据平台来决定，iOS包使用PVRTC，WinPhone包使用S3TC，Android包使用ETC，因为ETC是所有安卓设备都支持的纹理压缩格式。

但是ETC1并不支持Alpha通道，所以我们可以通过一些折中的手段让ETC1支持Alpha通道。

### 12.4.3　使ETC1支持透明

要使ETC支持透明通道有两种方法，一种是使用图集，将Alpha通道合并到图集中，通过修改Shader来实现；另外一种方法是将Alpha通道单独提取出来，然后使用多重纹理，在Shader中进行处理。下面我们会在Cocos2d-x中演示这两种方法的操作，图集和Alpha通道可以用Mali GPU纹理压缩工具生成。工具的下载地址是：http://malideveloper.arm.com/cn/develop-for-mali/tools/asset-creation/mali-gpu-texture-compression-tool/#mali-gpu-texture-compression-tool-download。

页面加载完后，单击页面开头处的下载版本会弹出如图12-23所示的对话框，根据操作系统来选择要下载哪个安装包。下载该工具需要安装Java环境，安装完Java环境后可以运行该工具，在Alpha handing中可以选择如何处理Alpha通道。该工具可以将一个普通的PNG图片输出为ETC压缩纹理，如图12-24所示。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155424.jpeg)

图12-23　下载纹理压缩工具

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155425.jpeg)

图12-24　压缩纹理

使用图集方法的好处是改动较少，使用方便，缺点是不能正确地实现纹理环绕，并且容易导致纹理过大。例如，笔者的PNG已经是由N多张PNG组成的Plist图集，再将Alpha通道抽出来合并为ETC图集，图片会变得很大，但对这种图集使用该方法，仍然是能够正常地显示Alpha。如图12-25所示为使用工具合成的ETC图集，以及将其进行Alpha处理之后的效果。可以看到，图片分为上下两部分，我们的做法是获取黑白部分纹理的颜色，用这个颜色来充当Alpha值，并只渲染有内容的部分。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155426.jpeg)

图12-25　ETC透明纹理

首先需要两个简单的Shader文件，一个顶点渲染器以及一个片段渲染器，顶点渲染器MyEtcAlpha.vert内容如下，将要渲染的纹理坐标的Y轴偏移0.5，得出对应的Alpha图片的坐标，因为整张图片的高度为1，偏移一半就是0.5。

```
attribute vec4 a_position;
attribute vec2 a_texCoord;
varying vec2 v_texCoord;
varying vec2 v_alphaCoord;
void main()
{
    gl_Position = CC_PMatrix * a_position;
    v_texCoord = a_texCoord;
    v_alphaCoord =  v_texCoord + vec2(0.0, 0.5);
}
```

MyEtcAlpha.frag内容如下，将顶点Shader算出来的v_alphaCoord，也就是对应Alpha图的纹理坐标，从图片中取出该坐标点的颜色，根据其R值进行判断，如果是白色，则RGB都为1，黑色则RGB都为0，灰色是处于两者之间。我们取出这个颜色，然后将其R值作为透明度，也就是最终要渲染的纹理的透明度，并将这个颜色进行渲染。

```
varying vec2 v_texCoord;
varying vec2 v_alphaCoord;
void main()
{
    vec4 v4Colour=texture2D(CC_Texture0, v_texCoord);
    v4Colour.a= texture2D(CC_Texture0, v_alphaCoord).r ;
    gl_FragColor=v4Colour;
}
```

那么，在Cocos2d-x中要如何使用上面这两个Shader呢？先将脚本和ETC图片都放到程序的资源目录下，然后使用下面的代码来使其透明：

```
//加载ETC图片，后缀名为pkm
auto sprite = Sprite::create("testAlpha.pkm");
auto size = Director::getInstance()->getWinSize();
sprite->setPosition(size * 0.5f);
//因为要显示的是一半，所以需要手动设置TextureRect
//也可以不设置，然后进行缩放，这需要稍微修改一下Shader
auto rectSize = sprite->getTextureRect().size;
sprite->setTextureRect(Rect(0.0f, 0.0f, rectSize.width, 0.5f *
rectSize.height));
//设置Blend，如果没有设置，透明通道不会生效
sprite->setBlendFunc(cocos2d::BlendFunc::ALPHA_NON_PREMULTIPLIED);
//创建Shader，并设置给sprite
GLProgram* program = GLProgram::createWithFilenames("MyEtcAlpha.vert", 
"MyEtcAlpha.frag");
sprite->setGLProgram(program);
addChild(sprite);
```

如果不希望使用setTextureRect方法，可以将MyEtcAlpha.vert中的v_texCoord = a_texCoord;修改为v_texCoord = a_texCoord * vec2(1.0, 0.5);，然后再把代码中的setTextureRect去掉，这样就不需要设置Rect了，但需要将图片的Y轴方向缩小一半才能得到所期望的显示，如图12-26所示。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155427.jpeg)

图12-26　去掉setTextureRect

另外，如果将setBlendFunc去掉，那么显示的结果将不会透明，会是如图12-27所示的效果。

![img](https://gitee.com/nlpleaf/PicGo/raw/master/20200707155428.jpeg)

图12-27　去掉setBlendFunc

开发者完全有理由不使用ETC图集而将透明通道单独分开，可以使用单独的Alpha图片或者将Alpha通道抽出来，单独生成一张ETC，工具的其他Alpha处理选项是支持这么做的。不论使用的透明通道图片是Alpha图还是ETC，处理都是一样的，即使用多重纹理，因此Shader代码要做少许修改。将MyEtcAlpha.vert的main函数调整如下，去掉v_alphaCoord变量。

```
gl_Position = CC_PMatrix * a_position;
v_texCoord = a_texCoord;
```

然后将MyEtcAlpha.frag的main函数调整如下，对于Alpha值，从CC_Texture1中取出，也就是第二张纹理，默认的纹理是从0开始，因为两张纹理尺寸一样，所以纹理坐标也是一一对应的。这里直接根据相同的纹理坐标，从第二张纹理取出R的值作为透明度即可。

```
vec4 v4Colour=texture2D(CC_Texture0,v_texCoord);
v4Colour.a= texture2D(CC_Texture1,v_texCoord).r ;
gl_FragColor=v4Colour;
```

代码也不麻烦，在设置完Shader之后，将Alpha纹理绑定到第二层纹理中，并将这个纹理设置到Shader的Uniform中，最后调用glActiveTexture重新激活默认的GL_TEXTURE0。下面的代码只需要在创建时运行一次即可。alphaTex是Alpha通道纹理的Texture2D对象。

```
Texture2D* alphaTex = Director::getInstance()->getTextureCache()->
addImage("alphaTex.pkm");
glActiveTexture(GL_TEXTURE1);
glBindTexture(GL_TEXTURE_2D, alphaTex->getName());
sprite->getGLProgramState()->setUniformTexture(GLProgram::UNIFORM_NAME_SAMPLER1, alphaTex);
glActiveTexture(GL_TEXTURE0);
```

上面的代码对于Cocos2d-x 3.0之前的版本，应该也是适用的。本章用到了一些Shader方面的知识，但没有详细介绍，如果读者希望详细了解Shader，在高级卷中的“**使用Shader**”一章中有比较详细的介绍。